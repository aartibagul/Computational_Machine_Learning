{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import wave, struct, numpy as np, matplotlib.mlab as mlab, pylab as pl\n",
    "\n",
    "filename = \"CML_Recording_Both.wav\"\n",
    "w = wave.open(filename,\"rb\")\n",
    "\n",
    "#returns a named tuple (nchannels, sampwidth, framerate, \n",
    "# nframes, comptype, compname)\n",
    "waveParams = w.getparams()\n",
    "\n",
    "s = w.readframes(waveParams[3])\n",
    "w.close()\n",
    "waveArray = np.fromstring(s, np.int16)\n",
    "\n",
    "spectrum, freq, bins = mlab.specgram(waveArray, NFFT=256,Fs=waveParams[2],sides='onesided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 11263)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# divergence\n",
    "def div(v,W,h):\n",
    "    whv = np.dot(W,h) * 1/v\n",
    "    div = whv - np.log(whv) - 1\n",
    "    div = np.dot( div, np.ones(div.shape) )\n",
    "    return div\n",
    "\n",
    "# divergence gradient\n",
    "def div_grad(v,W,h):\n",
    "    grad = np.dot( 1/v - 1/(np.dot(W,h)) , W)\n",
    "    return grad\n",
    "\n",
    "# epsilon divergence\n",
    "def compute_obj(v,W,h,eps):\n",
    "    \n",
    "    whv = (np.dot(W,h) + eps)/(v + eps)\n",
    "    if any(whv < 0):\n",
    "        print(W)\n",
    "        print(h)\n",
    "        print(v)\n",
    "        print('whv: ' + str(whv))\n",
    "    #print('whv.shape: ' + str(whv.shape))\n",
    "    #print('np.dot(W,h): ' + str(np.dot(W,h)))\n",
    "    div = whv - np.log(whv) - 1\n",
    "    #print(div)\n",
    "    return np.sum( div )\n",
    "\n",
    "# epsilon divergence gradient\n",
    "def compute_grad(v,W,h,eps):\n",
    "    #print('compute_grad start')\n",
    "    #print('W.shape: ' + str(W.shape))\n",
    "    #print('h.shape: ' + str(h.shape))\n",
    "    #print('v.shape: ' + str(v.shape))\n",
    "    #print('np.dot(W,h).shape: ' + str( (np.dot(W,h) + eps).shape ) )\n",
    "    #print((1/(v + eps) - 1/(np.dot(W,h) + eps)).shape)\n",
    "    grad = np.dot(W.T, (1/(v + eps) - 1/(np.dot(W,h) + eps)))\n",
    "    #print('compute_grad end')\n",
    "    return grad\n",
    "\n",
    "def itakura_saito(y,x):\n",
    "    y = np.array(y)\n",
    "    x = np.array(x)\n",
    "    return np.dot((y/x - np.log(y/x) -1) , np.ones(y.shape))\n",
    "    \n",
    "def get_h(eps,W,H, v):\n",
    "    \n",
    "\n",
    "    div = [0]* H.T.shape[0]\n",
    "    for i, h in enumerate(H.T):\n",
    "        div[i] = itakura_saito(eps+v, eps+np.dot(W,h))\n",
    "    \n",
    "    index = np.argmin(div)\n",
    "    return np.array(H.T[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.69910175]\n",
      " [-1.71243841]]\n",
      "[[-1.69909899]\n",
      " [-1.71243592]]\n"
     ]
    }
   ],
   "source": [
    "def grad_checker(v, W, h):\n",
    "    eps = 1e-3\n",
    "    (f,k) = W.shape\n",
    "    t_grad = np.zeros(h.shape)\n",
    "    for i in range(k):\n",
    "        ei = np.zeros(h.shape)\n",
    "        ei[i] = eps\n",
    "        t_grad[i] = (compute_obj(v,W,h+ei, 1e-12) - compute_obj(v,W,h-ei,1e-12)) / (2*eps)\n",
    "    print(t_grad)\n",
    "    print(compute_grad(v,W,h,1e-12))\n",
    "grad_checker(np.random.rand(2,1), np.random.rand(2,2),np.random.rand(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_backtracking(v, W, h, max_iter, compute_grad, compute_obj, eps):\n",
    "    \n",
    "    v = v.reshape(v.shape[0],1)\n",
    "  \n",
    "    beta = 0.5 #backstep factor between 0.1 and 0.8\n",
    "    opt_prec = 1-1e-4 # optimization precision\n",
    "    n = 1e-1 #initial step size\n",
    "    \n",
    "    h = np.random.rand(2, 1)\n",
    "    \n",
    "    obj = [None]*max_iter\n",
    "    \n",
    "    max_backstep = 100 # maximum number of backsteps\n",
    "    t = 0 # backstepping counter\n",
    "    k = 0 # gradient step counter \n",
    "    \n",
    "    while( k < max_iter and t != max_backstep ):\n",
    "        \n",
    "        grad = compute_grad(v,W,h,eps)\n",
    "        obj[k] = compute_obj(v,W,h,eps)\n",
    "        \n",
    "        t = 0 # reset backstepping counter\n",
    "        n = 1/beta*n # try to increase stepsize slightly again\n",
    "        \n",
    "        # make sure h-n*grad is positive\n",
    "        while(any(h - n * grad < 0)  and t < max_backstep ):\n",
    "            t += 1\n",
    "            n = beta * n\n",
    "    \n",
    "        new_obj = compute_obj(v,W,(h - n*grad),eps)\n",
    "        while( new_obj > opt_prec * compute_obj(v,W,h,eps) and t < max_backstep):\n",
    "            t += 1\n",
    "            n = beta * n\n",
    "            new_obj = abs(compute_obj(v,W,(h - n*grad),eps))\n",
    "                      \n",
    "        h = h - n * grad # update h according to gradient step\n",
    "        k += 1 # update gradient step counter\n",
    "       \n",
    "   \n",
    "    return h, obj[0:k]\n",
    "\n",
    "h, obj = gradient_backtracking(np.random.rand(10,1), np.random.rand(10,2),  np.random.rand(2, 1), 100, compute_grad, compute_obj, 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.774082161014455, 4.0980561340699637, 0.80890403809538192]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEKCAYAAADgl7WbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRGJAyVxEJAaUzEVEYkDJXEQkBv4P2qtnz9QYXXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111ea7dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = [i for i in range(10)]\n",
    "plt.title(\"On training data\")\n",
    "plt.plot([i for i in range(len(obj))], obj)\n",
    "\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 2)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def online_nmf(spectrum, W, H,A, B, rho, beta, n, eps):\n",
    "   \n",
    "    a = np.zeros(W.shape)\n",
    "    b = np.zeros(W.shape)\n",
    "\n",
    "    t = 1\n",
    "    W_old = W\n",
    "    k = W.shape[1]\n",
    "    h = np.random.rand(W.shape[1], 1)\n",
    "    h_old = h\n",
    "    while np.linalg.norm(W - W_old, ord = \"fro\") < n:\n",
    "        \n",
    "        t = t+1 \n",
    "        \n",
    "        ind = random.randint(0, len(spectrum.T))\n",
    "        v = spectrum.T[ind]\n",
    "        h_old = h\n",
    "        h, obj = gradient_backtracking(v, W, h_old, 100, compute_grad, compute_obj, 1e-12)\n",
    "   \n",
    "        h = h.reshape(h.shape[0],1)\n",
    "        v = v.reshape(v.shape[0],1)\n",
    "        den = eps + np.dot(W, h)\n",
    "        \n",
    "        a += np.dot(np.dot(((eps+v)/(den**2)), h.T), np.dot(W.T,W))\n",
    "        b += np.dot(1/den, h.T)\n",
    "        \n",
    "        if t % beta == 0:\n",
    "            A = A + rho*a\n",
    "            a = 0\n",
    "            B = B + rho*b\n",
    "            b = 0\n",
    "            W_old = W\n",
    "            W = np.sqrt(A/B)\n",
    "            \n",
    "            W = np.array([x/sum(x) for x in zip(*W)]).T\n",
    "            A = np.array([x/sum(x) for x in zip(*A)]).T\n",
    "            B = np.array([x*sum(x) for x in zip(*B)]).T\n",
    "            \n",
    "        if t > 30:\n",
    "            print(W.shape)\n",
    "            break\n",
    "\n",
    "eps = 1e-12\n",
    "v = spectrum.T[0]\n",
    "K = 2\n",
    "W = np.random.rand(spectrum.shape[0],K)\n",
    "H = np.zeros((K, spectrum.shape[1]))\n",
    "\n",
    "A = np.zeros(W.shape)\n",
    "B = np.zeros(W.shape)\n",
    "\n",
    "\n",
    "online_nmf(spectrum, W, H, A, B, 0.5, 100, 1e-3, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-12\n",
    "random.seed(12222015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = [sum(x) for x in zip(*W)]\n",
    "W = [sum(x) for x in zip(*W)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 129)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.array([[1,1], [1,2], [2,2]])\n",
    "X = [1,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25  0.25  0.5 ]\n",
      "[0 0 0]\n",
      "[ 0.2  0.4  0.4]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = W.T\n",
    "for i in range(2):\n",
    "    \n",
    "    col_sum = X[i].sum()\n",
    "    print(X[i]/col_sum)\n",
    "    X[i] = (X[i]/col_sum)\n",
    "    print(X[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.array([x/sum(x) for x in zip(*W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25,  0.2 ],\n",
       "       [ 0.25,  0.4 ],\n",
       "       [ 0.5 ,  0.4 ]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# divergence\n",
    "def div(v,W,h):\n",
    "    whv = np.dot(W,h) * 1/v\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones )\n",
    "    return div\n",
    "\n",
    "# divergence gradient\n",
    "def div_grad(v,W,h):\n",
    "    grad = np.dot( 1/v - 1/(np.dot(W,h)) , W)\n",
    "    return grad\n",
    "\n",
    "# epsilon divergence\n",
    "def eps_div(v,W,h,eps):\n",
    "    whv = (np.dot(W,h) + eps) * 1/(v + eps)\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones )\n",
    "    return div\n",
    "\n",
    "# epsilon divergence gradient\n",
    "def eps_div_grad(v,W,h,eps):\n",
    "    grad = np.dot( 1/(v + eps) - 1/(np.dot(W,h) + eps), W)\n",
    "    return grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
