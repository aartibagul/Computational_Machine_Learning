{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import wave, struct, numpy as np, matplotlib.mlab as mlab, pylab as pl\n",
    "\n",
    "filename = \"CML_Recording_Both.wav\"\n",
    "w = wave.open(filename,\"rb\")\n",
    "\n",
    "#returns a named tuple (nchannels, sampwidth, framerate, \n",
    "# nframes, comptype, compname)\n",
    "waveParams = w.getparams()\n",
    "\n",
    "s = w.readframes(waveParams[3])\n",
    "w.close()\n",
    "waveArray = np.fromstring(s, np.int16)\n",
    "\n",
    "spectrum, freq, bins = mlab.specgram(waveArray, NFFT=256,Fs=waveParams[2],sides='onesided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 11263)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# divergence\n",
    "def div(v,W,h):\n",
    "    whv = np.dot(W,h) * 1/v\n",
    "    div = whv - np.log(whv) - 1\n",
    "    div = np.dot( div, np.ones(div.shape) )\n",
    "    return div\n",
    "\n",
    "# divergence gradient\n",
    "def div_grad(v,W,h):\n",
    "    grad = np.dot( 1/v - 1/(np.dot(W,h)) , W)\n",
    "    return grad\n",
    "\n",
    "# epsilon divergence\n",
    "def compute_obj(v,W,h,eps):\n",
    "    \n",
    "    whv = (np.dot(W,h) + eps)/(v + eps)\n",
    "    if any(whv < 0):\n",
    "        print(W)\n",
    "        print(h)\n",
    "        print(v)\n",
    "        print('whv: ' + str(whv))\n",
    "    #print('whv.shape: ' + str(whv.shape))\n",
    "    #print('np.dot(W,h): ' + str(np.dot(W,h)))\n",
    "    div = whv - np.log(whv) - 1\n",
    "    #print(div)\n",
    "    return np.sum( div )\n",
    "\n",
    "# epsilon divergence gradient\n",
    "def compute_grad(v,W,h,eps):\n",
    "    #print('compute_grad start')\n",
    "    #print('W.shape: ' + str(W.shape))\n",
    "    #print('h.shape: ' + str(h.shape))\n",
    "    #print('v.shape: ' + str(v.shape))\n",
    "    #print('np.dot(W,h).shape: ' + str( (np.dot(W,h) + eps).shape ) )\n",
    "    #print((1/(v + eps) - 1/(np.dot(W,h) + eps)).shape)\n",
    "    grad = np.dot(W.T, (1/(v + eps) - 1/(np.dot(W,h) + eps)))\n",
    "    #print('compute_grad end')\n",
    "    return grad\n",
    "\n",
    "def itakura_saito(y,x):\n",
    "    y = np.array(y)\n",
    "    x = np.array(x)\n",
    "    return np.dot((y/x - np.log(y/x) -1) , np.ones(y.shape))\n",
    "    \n",
    "def get_h(eps,W,H, v):\n",
    "    \n",
    "\n",
    "    div = [0]* H.T.shape[0]\n",
    "    for i, h in enumerate(H.T):\n",
    "        div[i] = itakura_saito(eps+v, eps+np.dot(W,h))\n",
    "    \n",
    "    index = np.argmin(div)\n",
    "    return np.array(H.T[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.69910175]\n",
      " [-1.71243841]]\n",
      "[[-1.69909899]\n",
      " [-1.71243592]]\n"
     ]
    }
   ],
   "source": [
    "def grad_checker(v, W, h):\n",
    "    eps = 1e-3\n",
    "    (f,k) = W.shape\n",
    "    t_grad = np.zeros(h.shape)\n",
    "    for i in range(k):\n",
    "        ei = np.zeros(h.shape)\n",
    "        ei[i] = eps\n",
    "        t_grad[i] = (compute_obj(v,W,h+ei, 1e-12) - compute_obj(v,W,h-ei,1e-12)) / (2*eps)\n",
    "    print(t_grad)\n",
    "    print(compute_grad(v,W,h,1e-12))\n",
    "grad_checker(np.random.rand(2,1), np.random.rand(2,2),np.random.rand(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t to positive value: 0\n",
      "old_obj: 5.13001589421\n",
      "t to better objective =  2\n",
      "H is  [[ 1.14409319]\n",
      " [ 1.00867054]]\n",
      "t to positive value: 0\n",
      "old_obj: 2.76330257447\n",
      "t to better objective =  0\n",
      "H is  [[ 0.92004347]\n",
      " [ 0.81726406]]\n",
      "t to positive value: 0\n",
      "old_obj: 2.10960500346\n",
      "t to better objective =  0\n",
      "H is  [[ 0.70521131]\n",
      " [ 0.64448228]]\n",
      "t to positive value: 0\n",
      "old_obj: 2.02480137212\n",
      "t to better objective =  1\n",
      "H is  [[ 0.84142268]\n",
      " [ 0.78163074]]\n",
      "t to positive value: 0\n",
      "old_obj: 2.01822651541\n",
      "t to better objective =  1\n",
      "H is  [[ 0.71820579]\n",
      " [ 0.68112178]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.9974304061\n",
      "t to better objective =  1\n",
      "H is  [[ 0.80602187]\n",
      " [ 0.76424754]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.99337559494\n",
      "t to better objective =  1\n",
      "H is  [[ 0.72974591]\n",
      " [ 0.70073103]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.98661837171\n",
      "t to better objective =  1\n",
      "H is  [[ 0.78704534]\n",
      " [ 0.75311681]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.9845365587\n",
      "t to better objective =  1\n",
      "H is  [[ 0.73858896]\n",
      " [ 0.71211037]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.98208219495\n",
      "t to better objective =  2\n",
      "H is  [[ 0.75732181]\n",
      " [ 0.72890238]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.9787166369\n",
      "t to better objective =  100\n",
      "H is  [[ 0.75732181]\n",
      " [ 0.72890238]]\n"
     ]
    }
   ],
   "source": [
    "def gradient_backtracking(max_iter, W,  v, compute_grad, compute_obj, eps):\n",
    "    \n",
    "    v = v.reshape(v.shape[0],1)\n",
    "  \n",
    "    beta = 0.5 #backstep factor between 0.1 and 0.8\n",
    "    opt_prec = 1-1e-4 # optimization precision\n",
    "    n = 1e-1 #initial step size\n",
    "    \n",
    "    h = np.random.rand(2, 1)\n",
    "    \n",
    "    obj = [None]*max_iter\n",
    "    \n",
    "    max_backstep = 100 # maximum number of backsteps\n",
    "    t = 0 # backstepping counter\n",
    "    k = 0 # gradient step counter \n",
    "    \n",
    "    while( k < max_iter and t != max_backstep ):\n",
    "        \n",
    "        grad = compute_grad(v,W,h,eps)\n",
    "        obj[k] = compute_obj(v,W,h,eps)\n",
    "        \n",
    "        t = 0 # reset backstepping counter\n",
    "        n = 1/beta*n # try to increase stepsize slightly again\n",
    "        \n",
    "        # make sure h-n*grad is positive\n",
    "        while(any(h - n * grad < 0)  and t < max_backstep ):\n",
    "            t += 1\n",
    "            n = beta * n\n",
    "    \n",
    "        new_obj = compute_obj(v,W,(h - n*grad),eps)\n",
    "        while( new_obj > opt_prec * compute_obj(v,W,h,eps) and t < max_backstep):\n",
    "            t += 1\n",
    "            n = beta * n\n",
    "            new_obj = abs(compute_obj(v,W,(h - n*grad),eps))\n",
    "                      \n",
    "        h = h - n * grad # update h according to gradient step\n",
    "        k += 1 # update gradient step counter\n",
    "        \n",
    "    return h, obj[0:k]\n",
    "\n",
    "h, obj = gradient_backtracking(50, np.random.rand(10,2),   np.random.rand(10,1), compute_grad, compute_obj, 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.130015894210711, 2.7633025744651469, 2.109605003458356, 2.0248013721151534, 2.0182265154112851, 1.9974304060955446, 1.993375594939029, 1.9866183717106511, 1.9845365586958867, 1.9820821949535277, 1.9787166368990663]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzcxyxEndzCxHnNTNzHLk/wM0FUTFpWCJlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ded1f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = [i for i in range(10)]\n",
    "plt.title(\"On training data\")\n",
    "plt.plot([i for i in range(len(obj))], obj)\n",
    "\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 2)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def online_nmf(spectrum, W, H,A, B, rho, beta, n, eps):\n",
    "   \n",
    "    a = np.zeros(W.shape)\n",
    "    b = np.zeros(W.shape)\n",
    "\n",
    "    t = 1\n",
    "    W_old = W\n",
    "    k = W.shape[1]\n",
    "    while np.linalg.norm(W - W_old, ord = \"fro\") < n:\n",
    "        \n",
    "        t = t+1 \n",
    "        \n",
    "        ind = random.randint(0, len(spectrum.T))\n",
    "        v = spectrum.T[ind]\n",
    "        h = get_h(eps,W,H, v)\n",
    "        h = h.reshape(h.shape[0],1)\n",
    "        v = v.reshape(v.shape[0],1)\n",
    "        den = eps + np.dot(W, h)\n",
    "        \n",
    "        a += np.dot(np.dot(((eps+v)/(den**2)), h.T), np.dot(W.T,W))\n",
    "        b += np.dot(1/den, h.T)\n",
    "        \n",
    "        if t % beta == 0:\n",
    "            A = A + rho*a\n",
    "            a = 0\n",
    "            B = B + rho*b\n",
    "            b = 0\n",
    "            W_old = W\n",
    "            W = np.sqrt(A/B)\n",
    "            \n",
    "            W = np.array([x/sum(x) for x in zip(*W)]).T\n",
    "            A = np.array([x/sum(x) for x in zip(*A)]).T\n",
    "            B = np.array([x*sum(x) for x in zip(*B)]).T\n",
    "            \n",
    "        if t > 30:\n",
    "            print(W.shape)\n",
    "            break\n",
    "\n",
    "eps = 1e-12\n",
    "v = spectrum.T[0]\n",
    "K = 2\n",
    "W = np.random.rand(spectrum.shape[0],K)\n",
    "H = np.zeros((K, spectrum.shape[1]))\n",
    "\n",
    "A = np.zeros(W.shape)\n",
    "B = np.zeros(W.shape)\n",
    "\n",
    "\n",
    "online_nmf(spectrum, W, H, A, B, 0.5, 100, 1e-3, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-12\n",
    "random.seed(12222015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = [sum(x) for x in zip(*W)]\n",
    "W = [sum(x) for x in zip(*W)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 129)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.array([[1,1], [1,2], [2,2]])\n",
    "X = [1,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25  0.25  0.5 ]\n",
      "[0 0 0]\n",
      "[ 0.2  0.4  0.4]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = W.T\n",
    "for i in range(2):\n",
    "    \n",
    "    col_sum = X[i].sum()\n",
    "    print(X[i]/col_sum)\n",
    "    X[i] = (X[i]/col_sum)\n",
    "    print(X[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.array([x/sum(x) for x in zip(*W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25,  0.2 ],\n",
       "       [ 0.25,  0.4 ],\n",
       "       [ 0.5 ,  0.4 ]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# divergence\n",
    "def div(v,W,h):\n",
    "    whv = np.dot(W,h) * 1/v\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones )\n",
    "    return div\n",
    "\n",
    "# divergence gradient\n",
    "def div_grad(v,W,h):\n",
    "    grad = np.dot( 1/v - 1/(np.dot(W,h)) , W)\n",
    "    return grad\n",
    "\n",
    "# epsilon divergence\n",
    "def eps_div(v,W,h,eps):\n",
    "    whv = (np.dot(W,h) + eps) * 1/(v + eps)\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones )\n",
    "    return div\n",
    "\n",
    "# epsilon divergence gradient\n",
    "def eps_div_grad(v,W,h,eps):\n",
    "    grad = np.dot( 1/(v + eps) - 1/(np.dot(W,h) + eps), W)\n",
    "    return grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
