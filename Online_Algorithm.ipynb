{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import wave, struct, numpy as np, matplotlib.mlab as mlab, pylab as pl\n",
    "\n",
    "filename = \"CML_Recording_Both.wav\"\n",
    "w = wave.open(filename,\"rb\")\n",
    "\n",
    "#returns a named tuple (nchannels, sampwidth, framerate, \n",
    "# nframes, comptype, compname)\n",
    "waveParams = w.getparams()\n",
    "\n",
    "s = w.readframes(waveParams[3])\n",
    "w.close()\n",
    "waveArray = np.fromstring(s, np.int16)\n",
    "\n",
    "spectrum, freq, bins = mlab.specgram(waveArray, NFFT=256,Fs=waveParams[2],sides='onesided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 11263)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# divergence\n",
    "def div(v,W,h):\n",
    "    whv = np.dot(W,h) * 1/v\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones(div.shape) )\n",
    "    return div\n",
    "\n",
    "# divergence gradient\n",
    "def div_grad(v,W,h):\n",
    "    grad = np.dot( 1/v - 1/(np.dot(W,h)) , W)\n",
    "    return grad\n",
    "\n",
    "# epsilon divergence\n",
    "def compute_obj(v,W,h,eps):\n",
    "    whv = (np.dot(W,h) + eps)/(v + eps)\n",
    "    #print('whv.shape: ' + str(whv.shape))\n",
    "    #print('np.dot(W,h): ' + str(np.dot(W,h).shape))\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    #print(div)\n",
    "    return np.sum( div )\n",
    "\n",
    "# epsilon divergence gradient\n",
    "def compute_grad(v,W,h,eps):\n",
    "    #print('compute_grad start')\n",
    "    #print('W.shape: ' + str(W.shape))\n",
    "    #print('h.shape: ' + str(h.shape))\n",
    "    #print('v.shape: ' + str(v.shape))\n",
    "    #print('np.dot(W,h).shape: ' + str( (np.dot(W,h) + eps).shape ) )\n",
    "    #print((1/(v + eps) - 1/(np.dot(W,h) + eps)).shape)\n",
    "    grad = np.dot(W.T, (1/(v + eps) - 1/(np.dot(W,h) + eps)))\n",
    "    #print('compute_grad end')\n",
    "    return grad\n",
    "\n",
    "def itakura_saito(y,x):\n",
    "    y = np.array(y)\n",
    "    x = np.array(x)\n",
    "    return np.dot((y/x - np.log(y/x) -1) , np.ones(y.shape))\n",
    "    \n",
    "def get_h(eps,W,H, v):\n",
    "    \n",
    "    \n",
    "    div = [0]* H.T.shape[0]\n",
    "    for i, h in enumerate(H.T):\n",
    "        div[i] = itakura_saito(eps+v, eps+np.dot(W,h))\n",
    "    \n",
    "    index = np.argmin(div)\n",
    "    return np.array(H.T[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t =  11\n",
      "H is  [[ 0.21110607]\n",
      " [ 0.05567414]]\n",
      "t =  15\n",
      "H is  [[ 0.27425916]\n",
      " [ 0.14737224]]\n",
      "t =  15\n",
      "H is  [[ 0.27516872]\n",
      " [ 0.14856775]]\n",
      "t =  15\n",
      "H is  [[ 0.27520032]\n",
      " [ 0.14860931]]\n",
      "t =  15\n",
      "H is  [[ 0.27520143]\n",
      " [ 0.14861077]]\n",
      "t =  15\n",
      "H is  [[ 0.27520147]\n",
      " [ 0.14861082]]\n",
      "t =  15\n",
      "H is  [[ 0.27520147]\n",
      " [ 0.14861082]]\n",
      "t =  15\n",
      "H is  [[ 0.27520147]\n",
      " [ 0.14861082]]\n",
      "t =  15\n",
      "H is  [[ 0.27520147]\n",
      " [ 0.14861082]]\n",
      "t =  15\n",
      "H is  [[ 0.27520147]\n",
      " [ 0.14861082]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:20: RuntimeWarning: invalid value encountered in log10\n"
     ]
    }
   ],
   "source": [
    "def gradient_backtracking(max_iter, W,  v, compute_grad, compute_obj, eps):\n",
    "    \n",
    "    v = v.reshape(v.shape[0],1)\n",
    "  \n",
    "    alpha = 0.1 # chosen between 0.01 and 0.3\n",
    "    beta = 0.8 #between 0.1 and 0.8\n",
    "    \n",
    "    n = 1 #initial step size\n",
    "    \n",
    "    h = np.random.rand(2, 1)\n",
    "    obj = [None]*max_iter\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        \n",
    "        grad = compute_grad(v,W,h,eps)\n",
    "        obj[k] = compute_obj(v,W,h,eps)\n",
    "        \n",
    "        t = 0\n",
    "        while( (compute_obj(v,W,(h - n*grad),eps) >= (compute_obj(v,W,h,eps)) or any(h - n* grad < 0) ) and t < 15):\n",
    "            t += 1\n",
    "            n = beta * n\n",
    "        \n",
    "        print (\"t = \", t)\n",
    "        \n",
    "        h = h - n * grad\n",
    "      \n",
    "        print (\"H is \" , h)\n",
    "    return h, obj\n",
    "\n",
    "h, obj = gradient_backtracking(10, np.random.rand(10,2),   np.random.rand(10,1), compute_grad, compute_obj, 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.459629362776429, -0.18189229742183743, -0.1197779686890672, -0.11272517746293576, -0.11247809390418873, -0.11246940174553932, -0.1124690959190312, -0.11246908515871934, -0.11246908478012396, -0.11246908476680384]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEKCAYAAAALoA6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e3fd630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = [i for i in range(10)]\n",
    "plt.title(\"On training data\")\n",
    "plt.plot([i for i in range(len(obj))], obj)\n",
    "\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def online_nmf(spectrum, W, H,A, B, rho, beta, n, eps):\n",
    "    A_list = []\n",
    "    B_list = []\n",
    "   \n",
    "    a = np.zeros(W.shape)\n",
    "    b = np.zeros(W.shape)\n",
    "\n",
    "    t = 1\n",
    "    W_old = W\n",
    "    k = W.shape[1]\n",
    "    while np.linalg.norm(W - W_old, ord = \"fro\") < n:\n",
    "        t = t+1 \n",
    "        \n",
    "        ind = random.randint(0, len(spectrum.T))\n",
    "        v = spectrum.T[ind]\n",
    "        h = get_h(eps,W,H, v)\n",
    "        h = h.reshape(h.shape[0],1)\n",
    "        v = v.reshape(v.shape[0],1)\n",
    "        den = eps + np.dot(W, h)\n",
    "        \n",
    "        a += np.dot(np.dot(((eps+v)/(den**2)), h.T), np.dot(W.T,W))\n",
    "        b += np.dot(1/den, h.T)\n",
    "        \n",
    "        if t % beta == 0:\n",
    "            A = A + rho*a\n",
    "            a = 0\n",
    "            B = B + rho*b\n",
    "            b = 0\n",
    "            W_old = W\n",
    "            W = np.sqrt(A/B)\n",
    "            \n",
    "            W = np.array([x/sum(x) for x in zip(*W)]).T\n",
    "            A = np.array([x/sum(x) for x in zip(*A)]).T\n",
    "            B = np.array([x*sum(x) for x in zip(*B)]).T\n",
    "            \n",
    "        if t > 30:\n",
    "            print(W.shape)\n",
    "            break\n",
    "\n",
    "eps = 1e-12\n",
    "v = spectrum.T[0]\n",
    "K = 2\n",
    "W = np.random.rand(spectrum.shape[0],K)\n",
    "H = np.zeros((K, spectrum.shape[1]))\n",
    "\n",
    "A = np.zeros(W.shape)\n",
    "B = np.zeros(W.shape)\n",
    "\n",
    "\n",
    "online_nmf(spectrum, W, H, A, B, 0.5, 100, 1e-3, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-12\n",
    "random.seed(12222015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = [sum(x) for x in zip(*W)]\n",
    "W = [sum(x) for x in zip(*W)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 129)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.array([[1,1], [1,2], [2,2]])\n",
    "X = [1,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25  0.25  0.5 ]\n",
      "[0 0 0]\n",
      "[ 0.2  0.4  0.4]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = W.T\n",
    "for i in range(2):\n",
    "    \n",
    "    col_sum = X[i].sum()\n",
    "    print(X[i]/col_sum)\n",
    "    X[i] = (X[i]/col_sum)\n",
    "    print(X[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.array([x/sum(x) for x in zip(*W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25,  0.2 ],\n",
       "       [ 0.25,  0.4 ],\n",
       "       [ 0.5 ,  0.4 ]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# divergence\n",
    "def div(v,W,h):\n",
    "    whv = np.dot(W,h) * 1/v\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones )\n",
    "    return div\n",
    "\n",
    "# divergence gradient\n",
    "def div_grad(v,W,h):\n",
    "    grad = np.dot( 1/v - 1/(np.dot(W,h)) , W)\n",
    "    return grad\n",
    "\n",
    "# epsilon divergence\n",
    "def eps_div(v,W,h,eps):\n",
    "    whv = (np.dot(W,h) + eps) * 1/(v + eps)\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones )\n",
    "    return div\n",
    "\n",
    "# epsilon divergence gradient\n",
    "def eps_div_grad(v,W,h,eps):\n",
    "    grad = np.dot( 1/(v + eps) - 1/(np.dot(W,h) + eps), W)\n",
    "    return grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
