{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import wave, struct, numpy as np, matplotlib.mlab as mlab, pylab as pl\n",
    "\n",
    "filename = \"CML_Recording_Both.wav\"\n",
    "w = wave.open(filename,\"rb\")\n",
    "\n",
    "#returns a named tuple (nchannels, sampwidth, framerate, \n",
    "# nframes, comptype, compname)\n",
    "waveParams = w.getparams()\n",
    "\n",
    "s = w.readframes(waveParams[3])\n",
    "w.close()\n",
    "waveArray = np.fromstring(s, np.int16)\n",
    "\n",
    "spectrum, freq, bins = mlab.specgram(waveArray, NFFT=256,Fs=waveParams[2],sides='onesided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 11263)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# divergence\n",
    "def div(v,W,h):\n",
    "    whv = np.dot(W,h) * 1/v\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones(div.shape) )\n",
    "    return div\n",
    "\n",
    "# divergence gradient\n",
    "def div_grad(v,W,h):\n",
    "    grad = np.dot( 1/v - 1/(np.dot(W,h)) , W)\n",
    "    return grad\n",
    "\n",
    "# epsilon divergence\n",
    "def compute_obj(v,W,h,eps):\n",
    "    \n",
    "    whv = (np.dot(W,h) + eps)/(v + eps)\n",
    "    if any(whv < 0):\n",
    "        print(W)\n",
    "        print(h)\n",
    "        print(v)\n",
    "        print('whv: ' + str(whv))\n",
    "    #print('whv.shape: ' + str(whv.shape))\n",
    "    #print('np.dot(W,h): ' + str(np.dot(W,h)))\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    #print(div)\n",
    "    return np.sum( div )\n",
    "\n",
    "# epsilon divergence gradient\n",
    "def compute_grad(v,W,h,eps):\n",
    "    #print('compute_grad start')\n",
    "    #print('W.shape: ' + str(W.shape))\n",
    "    #print('h.shape: ' + str(h.shape))\n",
    "    #print('v.shape: ' + str(v.shape))\n",
    "    #print('np.dot(W,h).shape: ' + str( (np.dot(W,h) + eps).shape ) )\n",
    "    #print((1/(v + eps) - 1/(np.dot(W,h) + eps)).shape)\n",
    "    grad = np.dot(W.T, (1/(v + eps) - 1/(np.dot(W,h) + eps)))\n",
    "    #print('compute_grad end')\n",
    "    return grad\n",
    "\n",
    "def itakura_saito(y,x):\n",
    "    y = np.array(y)\n",
    "    x = np.array(x)\n",
    "    return np.dot((y/x - np.log(y/x) -1) , np.ones(y.shape))\n",
    "    \n",
    "def get_h(eps,W,H, v):\n",
    "    \n",
    "    div = [0]* H.T.shape[0]\n",
    "    for i, h in enumerate(H.T):\n",
    "        div[i] = itakura_saito(eps+v, eps+np.dot(W,h))\n",
    "    \n",
    "    index = np.argmin(div)\n",
    "    return np.array(H.T[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.001]\n",
      " [ 0.   ]]\n",
      "[[ 0.   ]\n",
      " [ 0.001]]\n",
      "[[ 22.65781217]\n",
      " [  7.41270636]]\n",
      "[[ 20.67899693]\n",
      " [  6.92498441]]\n",
      "[[ 1.09569203]\n",
      " [ 1.07042932]]\n"
     ]
    }
   ],
   "source": [
    "def grad_checker(v, W, h):\n",
    "    eps = 1e-3\n",
    "    (f,k) = W.shape\n",
    "    t_grad = np.zeros(h.shape)\n",
    "    for i in range(k):\n",
    "        ei = np.zeros(h.shape)\n",
    "        ei[i] = eps\n",
    "        print(ei)\n",
    "        t_grad[i] = (compute_obj(v,W,h+ei, 1e-12) - compute_obj(v,W,h-ei,1e-12)) / (2*eps)\n",
    "    print(t_grad)\n",
    "    print(compute_grad(v,W,h,1e-12))\n",
    "    print(t_grad/compute_grad(v,W,h,1e-12))\n",
    "grad_checker(np.random.rand(2,1), np.random.rand(2,2),np.random.rand(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t to positive value: 0\n",
      "old_obj: 3.19794326492\n",
      "t to better objective =  0\n",
      "H is  [[ 0.27848951]\n",
      " [ 0.45710442]]\n",
      "t to positive value: 0\n",
      "old_obj: 2.58092696399\n",
      "t to better objective =  0\n",
      "H is  [[ 0.26515346]\n",
      " [ 0.43009119]]\n",
      "t to positive value: 0\n",
      "old_obj: 2.18615410094\n",
      "t to better objective =  0\n",
      "H is  [[ 0.2594665]\n",
      " [ 0.4111375]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.94825920757\n",
      "t to better objective =  0\n",
      "H is  [[ 0.25880728]\n",
      " [ 0.39767799]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.81050375511\n",
      "t to better objective =  0\n",
      "H is  [[ 0.26109504]\n",
      " [ 0.38766299]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.73187906991\n",
      "t to better objective =  0\n",
      "H is  [[ 0.26494576]\n",
      " [ 0.37971617]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.68644636467\n",
      "t to better objective =  0\n",
      "H is  [[ 0.26953897]\n",
      " [ 0.37301036]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.65917607057\n",
      "t to better objective =  0\n",
      "H is  [[ 0.27442136]\n",
      " [ 0.3670788 ]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.6417997862\n",
      "t to better objective =  0\n",
      "H is  [[ 0.2793531 ]\n",
      " [ 0.36166585]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.62989130646\n",
      "t to better objective =  0\n",
      "H is  [[ 0.28421125]\n",
      " [ 0.35663226]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.62110783792\n",
      "t to better objective =  0\n",
      "H is  [[ 0.28893484]\n",
      " [ 0.35190104]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.61420913885\n",
      "t to better objective =  0\n",
      "H is  [[ 0.2934953 ]\n",
      " [ 0.34742795]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.6085316116\n",
      "t to better objective =  0\n",
      "H is  [[ 0.29788081]\n",
      " [ 0.34318591]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.60371191124\n",
      "t to better objective =  0\n",
      "H is  [[ 0.30208821]\n",
      " [ 0.33915686]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.59954313762\n",
      "t to better objective =  0\n",
      "H is  [[ 0.30611875]\n",
      " [ 0.33532749]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.5959003711\n",
      "t to better objective =  0\n",
      "H is  [[ 0.30997596]\n",
      " [ 0.33168707]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.59270218898\n",
      "t to better objective =  0\n",
      "H is  [[ 0.31366452]\n",
      " [ 0.3282263 ]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.58989077716\n",
      "t to better objective =  0\n",
      "H is  [[ 0.31718965]\n",
      " [ 0.32493673]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.5874216325\n",
      "t to better objective =  0\n",
      "H is  [[ 0.32055684]\n",
      " [ 0.32181048]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.58525820644\n",
      "t to better objective =  0\n",
      "H is  [[ 0.32377165]\n",
      " [ 0.31884008]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.58336909278\n",
      "t to better objective =  0\n",
      "H is  [[ 0.32683965]\n",
      " [ 0.31601838]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.58172652498\n",
      "t to better objective =  0\n",
      "H is  [[ 0.32976635]\n",
      " [ 0.31333852]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.58030554755\n",
      "t to better objective =  0\n",
      "H is  [[ 0.33255719]\n",
      " [ 0.3107939 ]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57908353455\n",
      "t to better objective =  0\n",
      "H is  [[ 0.33521749]\n",
      " [ 0.30837819]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57803988754\n",
      "t to better objective =  0\n",
      "H is  [[ 0.33775248]\n",
      " [ 0.3060853 ]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57715582675\n",
      "t to better objective =  0\n",
      "H is  [[ 0.34016724]\n",
      " [ 0.30390936]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57641423161\n",
      "t to better objective =  0\n",
      "H is  [[ 0.34246674]\n",
      " [ 0.30184477]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57579950833\n",
      "t to better objective =  0\n",
      "H is  [[ 0.34465582]\n",
      " [ 0.29988613]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57529747317\n",
      "t to better objective =  0\n",
      "H is  [[ 0.34673917]\n",
      " [ 0.2980283 ]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57489524588\n",
      "t to better objective =  0\n",
      "H is  [[ 0.34872134]\n",
      " [ 0.29626632]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57458115051\n",
      "t to better objective =  0\n",
      "H is  [[ 0.35060674]\n",
      " [ 0.29459547]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57434462227\n",
      "t to better objective =  0\n",
      "H is  [[ 0.35239965]\n",
      " [ 0.29301123]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57417611979\n",
      "t to better objective =  0\n",
      "H is  [[ 0.35410418]\n",
      " [ 0.29150928]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.57406704257\n",
      "t to better objective =  0\n",
      "H is  [[ 0.35572432]\n",
      " [ 0.29008551]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.5740096533\n",
      "t to better objective =  0\n",
      "H is  [[ 0.3572639 ]\n",
      " [ 0.28873598]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.5739970051\n",
      "new_obj: 1.57400889259\n",
      "new_obj: 1.57400268736\n",
      "new_obj: 1.57399978088\n",
      "new_obj: 1.57399837665\n",
      "new_obj: 1.57399768679\n",
      "new_obj: 1.57399734492\n",
      "new_obj: 1.57399717476\n",
      "new_obj: 1.57399708986\n",
      "new_obj: 1.57399704746\n",
      "new_obj: 1.57399702628\n",
      "new_obj: 1.57399701569\n",
      "new_obj: 1.57399701039\n",
      "new_obj: 1.57399700774\n",
      "new_obj: 1.57399700642\n",
      "new_obj: 1.57399700576\n",
      "new_obj: 1.57399700543\n",
      "new_obj: 1.57399700526\n",
      "new_obj: 1.57399700518\n",
      "new_obj: 1.57399700514\n",
      "new_obj: 1.57399700512\n",
      "new_obj: 1.57399700511\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "t to better objective =  37\n",
      "H is  [[ 0.3572639 ]\n",
      " [ 0.28873598]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "t to better objective =  2\n",
      "H is  [[ 0.3572639 ]\n",
      " [ 0.28873598]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "t to better objective =  4\n",
      "H is  [[ 0.3572639 ]\n",
      " [ 0.28873598]]\n",
      "t to positive value: 0\n",
      "old_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "new_obj: 1.5739970051\n",
      "t to better objective =  100\n",
      "H is  [[ 0.3572639 ]\n",
      " [ 0.28873598]]\n"
     ]
    }
   ],
   "source": [
    "def gradient_backtracking(max_iter, W,  v, compute_grad, compute_obj, eps):\n",
    "    \n",
    "    v = v.reshape(v.shape[0],1)\n",
    "  \n",
    "    alpha = 0.1 # chosen between 0.01 and 0.3\n",
    "    beta = 0.5 #between 0.1 and 0.8\n",
    "    \n",
    "    n = 1e-2 #initial step size\n",
    "    \n",
    "    h = np.random.rand(2, 1)\n",
    "    obj = [None]*max_iter\n",
    "    \n",
    "    max_backstep = 100\n",
    "    t = 0\n",
    "    k = 0\n",
    "    while( k < max_iter and t != max_backstep ):\n",
    "        grad = compute_grad(v,W,h,eps)\n",
    "        obj[k] = compute_obj(v,W,h,eps)\n",
    "        \n",
    "        t = 0\n",
    "        # make sure h-n*grad is positive\n",
    "        while(any(h - n * grad < 0)  and t < max_backstep ):\n",
    "            t += 1\n",
    "            n = beta * n\n",
    "            \n",
    "        print('t to positive value: ' + str(t))\n",
    "        print('old_obj: ' + str(compute_obj(v,W,h,eps)))\n",
    "        new_obj = compute_obj(v,W,(h - n*grad),eps)\n",
    "        while( new_obj >= compute_obj(v,W,h,eps) and t < max_backstep):\n",
    "            t += 1\n",
    "            n = beta * n\n",
    "            new_obj = abs(compute_obj(v,W,(h - n*grad),eps))\n",
    "            print('new_obj: ' + str(new_obj))\n",
    "              \n",
    "        print (\"t to better objective = \", t)\n",
    "        \n",
    "        h = h - n * grad\n",
    "      \n",
    "        print (\"H is \" , h)\n",
    "        k += 1\n",
    "    return h, obj[0:k]\n",
    "\n",
    "h, obj = gradient_backtracking(50, np.random.rand(10,2),   np.random.rand(10,1), compute_grad, compute_obj, 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1979432649182726, 2.5809269639915962, 2.1861541009429608, 1.9482592075678364, 1.8105037551143139, 1.7318790699086741, 1.6864463646728525, 1.659176070567947, 1.6417997862004381, 1.6298913064649958, 1.6211078379231205, 1.6142091388485604, 1.6085316116043162, 1.6037119112377587, 1.5995431376185993, 1.595900371101199, 1.5927021889807502, 1.5898907771557202, 1.5874216324972197, 1.5852582064414475, 1.5833690927802997, 1.5817265249830701, 1.5803055475465175, 1.5790835345484577, 1.5780398875420678, 1.5771558267515338, 1.576414231614615, 1.5757995083337204, 1.5752974731722797, 1.5748952458828875, 1.574581150513771, 1.5743446222685802, 1.574176119791012, 1.5740670425706016, 1.5740096533045032, 1.5739970050972909, 1.5739970050972905, 1.5739970050972902, 1.57399700509729]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNzPLkf8P52LG8EiSW+8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e312e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = [i for i in range(10)]\n",
    "plt.title(\"On training data\")\n",
    "plt.plot([i for i in range(len(obj))], obj)\n",
    "\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def online_nmf(spectrum, W, H,A, B, rho, beta, n, eps):\n",
    "    A_list = []\n",
    "    B_list = []\n",
    "   \n",
    "    a = np.zeros(W.shape)\n",
    "    b = np.zeros(W.shape)\n",
    "\n",
    "    t = 1\n",
    "    W_old = W\n",
    "    k = W.shape[1]\n",
    "    while np.linalg.norm(W - W_old, ord = \"fro\") < n:\n",
    "        t = t+1 \n",
    "        \n",
    "        ind = random.randint(0, len(spectrum.T))\n",
    "        v = spectrum.T[ind]\n",
    "        h = get_h(eps,W,H, v)\n",
    "        h = h.reshape(h.shape[0],1)\n",
    "        v = v.reshape(v.shape[0],1)\n",
    "        den = eps + np.dot(W, h)\n",
    "        \n",
    "        a += np.dot(np.dot(((eps+v)/(den**2)), h.T), np.dot(W.T,W))\n",
    "        b += np.dot(1/den, h.T)\n",
    "        \n",
    "        if t % beta == 0:\n",
    "            A = A + rho*a\n",
    "            a = 0\n",
    "            B = B + rho*b\n",
    "            b = 0\n",
    "            W_old = W\n",
    "            W = np.sqrt(A/B)\n",
    "            \n",
    "            W = np.array([x/sum(x) for x in zip(*W)]).T\n",
    "            A = np.array([x/sum(x) for x in zip(*A)]).T\n",
    "            B = np.array([x*sum(x) for x in zip(*B)]).T\n",
    "            \n",
    "        if t > 30:\n",
    "            print(W.shape)\n",
    "            break\n",
    "\n",
    "eps = 1e-12\n",
    "v = spectrum.T[0]\n",
    "K = 2\n",
    "W = np.random.rand(spectrum.shape[0],K)\n",
    "H = np.zeros((K, spectrum.shape[1]))\n",
    "\n",
    "A = np.zeros(W.shape)\n",
    "B = np.zeros(W.shape)\n",
    "\n",
    "\n",
    "online_nmf(spectrum, W, H, A, B, 0.5, 100, 1e-3, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-12\n",
    "random.seed(12222015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = [sum(x) for x in zip(*W)]\n",
    "W = [sum(x) for x in zip(*W)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 129)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.array([[1,1], [1,2], [2,2]])\n",
    "X = [1,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25  0.25  0.5 ]\n",
      "[0 0 0]\n",
      "[ 0.2  0.4  0.4]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = W.T\n",
    "for i in range(2):\n",
    "    \n",
    "    col_sum = X[i].sum()\n",
    "    print(X[i]/col_sum)\n",
    "    X[i] = (X[i]/col_sum)\n",
    "    print(X[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.array([x/sum(x) for x in zip(*W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25,  0.2 ],\n",
       "       [ 0.25,  0.4 ],\n",
       "       [ 0.5 ,  0.4 ]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# divergence\n",
    "def div(v,W,h):\n",
    "    whv = np.dot(W,h) * 1/v\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones )\n",
    "    return div\n",
    "\n",
    "# divergence gradient\n",
    "def div_grad(v,W,h):\n",
    "    grad = np.dot( 1/v - 1/(np.dot(W,h)) , W)\n",
    "    return grad\n",
    "\n",
    "# epsilon divergence\n",
    "def eps_div(v,W,h,eps):\n",
    "    whv = (np.dot(W,h) + eps) * 1/(v + eps)\n",
    "    div = whv - np.log10(whv) - 1\n",
    "    div = np.dot( div, np.ones )\n",
    "    return div\n",
    "\n",
    "# epsilon divergence gradient\n",
    "def eps_div_grad(v,W,h,eps):\n",
    "    grad = np.dot( 1/(v + eps) - 1/(np.dot(W,h) + eps), W)\n",
    "    return grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
